{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b586387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce50d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"]=os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"]=os.getenv(\"MLFLOW_TRACKING_USERNAME\")\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"]=os.getenv(\"MLFLOW_TRACKING_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a1940d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvClassifier import logger\n",
    "from cvClassifier.utils.common import get_size, read_yaml, create_directories, save_json \n",
    "from cvClassifier.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe177ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelEvalConfig:\n",
    "    trained_model_path: Path\n",
    "    training_data_path: Path\n",
    "    validation_data_path: Path\n",
    "    test_data_path: Path\n",
    "    all_params: dict\n",
    "    params_image_size: list\n",
    "    params_batch_size: int\n",
    "    mlflow_uri: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b6c3cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09d2b112",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    # this class manages the configuration of the model evaluation pipeline\n",
    "\n",
    "    def __init__(self, config_filepath = CONFIG_FILE_PATH, params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        #create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_eval_config(self) -> ModelEvalConfig:\n",
    "        ''' Gets the config details for the model training pipeline '''\n",
    "        params = self.params\n",
    "        \n",
    "\n",
    "        model_eval_config = ModelEvalConfig(\n",
    "            training_data_path = self.config.model_training.training_data,\n",
    "            validation_data_path = self.config.model_training.validation_data,\n",
    "            test_data_path = self.config.model_training.test_data,\n",
    "            trained_model_path = self.config.model_training.trained_model_path,\n",
    "            all_params = params,\n",
    "            params_image_size = params.IMAGE_SIZE,\n",
    "            params_batch_size = params.BATCH_SIZE,\n",
    "            mlflow_uri = self.config.model_evaluation.mlflow_tracking_uri\n",
    "        )\n",
    "\n",
    "        return model_eval_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6c1158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningModel(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate=0.01):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.test_step_outputs = []\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = (outputs.argmax(dim=1) == labels).float().mean()\n",
    "        \n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', acc)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = (outputs.argmax(dim=1) == labels).float().mean()\n",
    "        \n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', acc)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = (outputs.argmax(dim=1) == labels).float().mean()\n",
    "        \n",
    "        # Store outputs for epoch-level metrics\n",
    "        self.test_step_outputs.append({'test_loss': loss, 'test_acc': acc})\n",
    "        \n",
    "        self.log('test_loss', loss, on_step=True, on_epoch=True)\n",
    "        self.log('test_acc', acc, on_step=True, on_epoch=True)\n",
    "        \n",
    "        return {'test_loss': loss, 'test_acc': acc}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        # Calculate average metrics\n",
    "        if self.test_step_outputs:\n",
    "            avg_loss = torch.stack([x['test_loss'] for x in self.test_step_outputs]).mean()\n",
    "            avg_acc = torch.stack([x['test_acc'] for x in self.test_step_outputs]).mean()\n",
    "            \n",
    "            self.log('avg_test_loss', avg_loss)\n",
    "            self.log('avg_test_acc', avg_acc)\n",
    "            \n",
    "            # Clear the list for next epoch\n",
    "            self.test_step_outputs.clear()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc91fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluation:\n",
    "    def __init__(self, config: ModelEvalConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def load_model(self, path: Path) -> nn.Module:\n",
    "        return torch.load(path)\n",
    "        logger.info(f\"Model loaded from {path}\")\n",
    "    \n",
    "    def test_generator(self):\n",
    "\n",
    "        # preparing the test dataset\n",
    "        test_transforms = transforms.Compose([\n",
    "            transforms.Resize(self.config.params_image_size[:-1]),  # Resize to target size\n",
    "            transforms.ToTensor(),  # Converts to tensor and scales to [0,1]\n",
    "        ])\n",
    "        \n",
    "        # load test dataset\n",
    "        test_dataset = datasets.ImageFolder(\n",
    "            root=self.config.test_data_path,\n",
    "            transform=test_transforms\n",
    "        )\n",
    "        logger.info(f\"Test dataset created from {self.config.test_data_path}\")\n",
    "        \n",
    "        self.test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=0\n",
    "        )\n",
    "        \n",
    "        \n",
    "        logger.info(f\"Test samples: {len(test_dataset)}\")\n",
    "        logger.info(f\"Number of classes: {len(test_dataset.classes)}\")\n",
    "        logger.info(f\"Classes: {test_dataset.classes}\")\n",
    "\n",
    "    \n",
    "    def evaluation(self):\n",
    "        \"\"\"Perform model evaluation using PyTorch Lightning\"\"\"\n",
    "\n",
    "        logger.info('Starting model evaluation...')\n",
    "        \n",
    "        self.model = self.load_model(self.config.trained_model_path)\n",
    "        self.model.eval()\n",
    "        \n",
    "        self.test_generator()\n",
    "        \n",
    "        lightning_model = LightningModel(self.model)\n",
    "        \n",
    "        trainer = pl.Trainer(\n",
    "            accelerator='auto',\n",
    "            devices='auto',\n",
    "            logger=False,  # Disable logging for evaluation\n",
    "            enable_progress_bar=True,\n",
    "            enable_model_summary=False,\n",
    "            enable_checkpointing=False,\n",
    "        )\n",
    "        \n",
    "        test_results = trainer.test(\n",
    "            model=lightning_model,\n",
    "            dataloaders=self.test_loader,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        if test_results and len(test_results) > 0:\n",
    "            self.scores = {\n",
    "                \"loss\": test_results[0].get('test_loss_epoch', 0.0),\n",
    "                \"accuracy\": test_results[0].get('test_acc_epoch', 0.0)\n",
    "            }\n",
    "            logger.info(f\"Evaluation completed!\")\n",
    "            logger.info(f\"Loss: {self.scores['loss']:.4f}\")\n",
    "            logger.info(f\"Accuracy: {self.scores['accuracy']:.4f}\")\n",
    "            \n",
    "        else:\n",
    "            logger.info('No results returned from evaluation.')\n",
    "        \n",
    "        self.save_score()\n",
    "    \n",
    "    \n",
    "    def log_into_mlflow(self):\n",
    "        mlflow.set_registry_uri(self.config.mlflow_uri)\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "        \n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "            mlflow.log_metrics(\n",
    "                {\"loss\": self.scores['loss'], \"accuracy\": self.scores['accuracy']}\n",
    "            )\n",
    "\n",
    "            # Model registry does not work with file store\n",
    "            if tracking_url_type_store != \"file\":\n",
    "\n",
    "                # Register the model\n",
    "                # There are other ways to use the Model Registry, which depends on the use case,\n",
    "                # please refer to the doc for more information:\n",
    "                # https://mlflow.org/docs/latest/model-registry.html#api-workflow\n",
    "                mlflow.pytorch.log_model(self.model, \"model\", registered_model_name=\"VGG16Model\")\n",
    "            else:\n",
    "                mlflow.pytorch.log_model(self.model, \"model\")\n",
    "\n",
    "    def save_score(self):\n",
    "        \"\"\"Save evaluation scores to JSON file\"\"\"\n",
    "\n",
    "        save_json(path=Path(\"scores.json\"), data=self.scores)\n",
    "        logger.info(f\"Scores saved to scores.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1c55a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-08 00:43:28,675: INFO: common]: yaml file successfully loaded from config/config.yaml\n",
      "[2025-07-08 00:43:28,676: INFO: common]: yaml file successfully loaded from params.yaml\n",
      "[2025-07-08 00:43:28,676: INFO: 1285874601]: Starting model evaluation...\n",
      "[2025-07-08 00:43:28,687: INFO: 1285874601]: Test dataset created from artifacts/data_ingestion/Data/test\n",
      "[2025-07-08 00:43:28,688: INFO: 1285874601]: Test samples: 315\n",
      "[2025-07-08 00:43:28,688: INFO: 1285874601]: Number of classes: 4\n",
      "[2025-07-08 00:43:28,688: INFO: 1285874601]: Classes: ['adenocarcinoma', 'large.cell.carcinoma', 'normal', 'squamous.cell.carcinoma']\n",
      "[2025-07-08 00:43:28,707: INFO: setup]: GPU available: True (mps), used: True\n",
      "[2025-07-08 00:43:28,708: INFO: setup]: TPU available: False, using: 0 TPU cores\n",
      "[2025-07-08 00:43:28,708: INFO: setup]: HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d9/1xz8vq817d3_x9b35qzvvgjc0000gn/T/ipykernel_58031/1285874601.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(path)\n",
      "/opt/anaconda3/envs/cv-cancer/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 20/20 [00:03<00:00,  5.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       avg_test_acc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.21676135063171387    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       avg_test_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.465147852897644     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_acc_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.21587301790714264    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_loss_epoch      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.4656859636306763     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      avg_test_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.21676135063171387   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      avg_test_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.465147852897644    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_acc_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.21587301790714264   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.4656859636306763    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-08 00:43:32,449: INFO: 1285874601]: Evaluation completed!\n",
      "[2025-07-08 00:43:32,449: INFO: 1285874601]: Loss: 1.4657\n",
      "[2025-07-08 00:43:32,449: INFO: 1285874601]: Accuracy: 0.2159\n",
      "[2025-07-08 00:43:32,450: INFO: common]: json file saved at scores.json\n",
      "[2025-07-08 00:43:32,450: INFO: 1285874601]: Scores saved to scores.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cv-cancer/lib/python3.8/site-packages/_distutils_hack/__init__.py:31: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "Registered model 'VGG16Model' already exists. Creating a new version of this model...\n",
      "2025/07/08 00:43:51 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: VGG16Model, version 6\n",
      "Created version '6' of model 'VGG16Model'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    eval_config = config.get_model_eval_config()\n",
    "    evaluation = ModelEvaluation(eval_config)\n",
    "    evaluation.evaluation()\n",
    "    evaluation.log_into_mlflow()\n",
    "\n",
    "except Exception as e:\n",
    "   raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-cancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
