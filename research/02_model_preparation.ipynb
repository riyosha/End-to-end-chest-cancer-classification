{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e5c228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe7cf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelPreparationConfig:\n",
    "    root_dir: Path\n",
    "    model_name: str\n",
    "    base_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    params_image_size: list\n",
    "    params_include_top: bool\n",
    "    params_classes: int\n",
    "    params_weights: str\n",
    "    params_learning_rate: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55b58e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvClassifier import logger\n",
    "from cvClassifier.utils.common import get_size, read_yaml, create_directories \n",
    "from cvClassifier.constants import *\n",
    "from torchvision.models import VGG16_Weights\n",
    "from torchvision.models import resnet50, ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81c60d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    # this class manages the configuration of the model preparation pipeline\n",
    "\n",
    "    def __init__(self, config_filepath = CONFIG_FILE_PATH, params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_preparation_config(self) -> ModelPreparationConfig:\n",
    "        ''' Gets the config details for the model preparation ingestion pipeline '''\n",
    "        config = self.config.model_preparation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_preparation_config = ModelPreparationConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            model_name = config.model_name,\n",
    "            base_model_path = f'{config.base_model_path}/base_model_{config.model_name}.pth',\n",
    "            updated_base_model_path = f'{config.updated_base_model_path}/updated_base_model_{config.model_name}.pth',\n",
    "            params_image_size = self.params.IMAGE_SIZE,\n",
    "            params_include_top= self.params.INCLUDE_TOP,\n",
    "            params_classes = self.params.CLASSES,\n",
    "            params_weights = self.params.WEIGHTS,\n",
    "            params_learning_rate = self.params.LEARNING_RATE\n",
    "        )\n",
    "\n",
    "        return model_preparation_config\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71487d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelFactory:\n",
    "    @staticmethod\n",
    "    def create_model(model_name: str, num_classes: int, pretrained: bool = True, include_top: bool = False, weights: str = 'imagenet'):\n",
    "        \"\"\"Create VGG16 or ResNet50 model\"\"\"\n",
    "        \n",
    "        if model_name.lower() == \"vgg16\":\n",
    "            weights = VGG16_Weights.IMAGENET1K_V1 if weights == 'imagenet' else None\n",
    "            model = models.vgg16(weights=weights)\n",
    "\n",
    "            if not include_top:\n",
    "                model = nn.Sequential(*list(model.features.children()))\n",
    "                # *list() unpacks the list of layers in the model.features and passes them as separate arguments to nn.Sequential\n",
    "            \n",
    "            logger.info(f\"Created VGG16 model with include_top={include_top}\")\n",
    "            \n",
    "        elif model_name.lower() == \"resnet50\":\n",
    "            weights = ResNet50_Weights.IMAGENET1K_V1 if weights == 'imagenet' else None\n",
    "            model = models.resnet50(weights=weights)\n",
    "\n",
    "            #if not include_top:\n",
    "                # Remove the final classification layer\n",
    "                #model = nn.Sequential(*list(model.children())[:-1])\n",
    "            \n",
    "            \n",
    "            logger.info(f\"Created ResNet50 model with include_top={include_top}\")\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {model_name}. Only 'vgg16' and 'resnet50' are supported.\")\n",
    "            \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cce6e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as requests\n",
    "from zipfile import ZipFile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.models import VGG16_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e92cb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelPreparation:\n",
    "    def __init__(self,config = ModelPreparationConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        \"\"\"Get base model using factory pattern\"\"\"\n",
    "        \n",
    "        # Create model using factory\n",
    "        self.model = ModelFactory.create_model(\n",
    "            model_name=self.config.model_name,\n",
    "            num_classes=self.config.params_classes,\n",
    "            pretrained=True,\n",
    "            include_top=self.config.params_include_top,\n",
    "            weights=self.config.params_weights\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"{self.config.model_name} model created successfully\")\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: nn.Module):\n",
    "        torch.save(model, path)\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_full_model(model, classes, freeze_all, freeze_till, learning_rate, model_name):\n",
    "        \n",
    "        if model_name.lower() == \"vgg16\":\n",
    "            if freeze_all:\n",
    "                for param in model.parameters():\n",
    "                    param.requires_grad = False\n",
    "            elif (freeze_till is not None) and (freeze_till > 0):\n",
    "                layers = list(model.children())\n",
    "                for layer in layers[:-freeze_till]:\n",
    "                    for param in layer.parameters():\n",
    "                        param.requires_grad = False\n",
    "\n",
    "            num_features = 512 * 7 * 7  # VGG16 features\n",
    "            \n",
    "            if isinstance(model, nn.Sequential):\n",
    "                base_layers = list(model.children())\n",
    "            else:\n",
    "                base_layers = list(model.features.children())\n",
    "                \n",
    "            full_model = nn.Sequential(\n",
    "                *base_layers,\n",
    "                nn.Flatten(), \n",
    "                nn.Linear(num_features, classes), \n",
    "            )\n",
    "                \n",
    "        elif model_name.lower() == \"resnet50\":\n",
    "            if freeze_all:\n",
    "                # Freeze all layers except layer4 (conv5)\n",
    "                for name, param in model.named_parameters():\n",
    "                    if 'layer4' not in name:\n",
    "                        param.requires_grad = False\n",
    "                        print(f\"Frozen: {name}\")\n",
    "                    else:\n",
    "                        param.requires_grad = True\n",
    "                        print(f\"Trainable: {name}\")\n",
    "            elif (freeze_till is not None) and (freeze_till > 0):\n",
    "                for name, param in model.named_parameters():\n",
    "                    if 'layer4' not in name:\n",
    "                        param.requires_grad = False\n",
    "\n",
    "            # For ResNet50, replace the fc layer\n",
    "            model.fc = nn.Linear(2048, classes)\n",
    "            full_model = model  # Use the full ResNet50 model\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(full_model.parameters(), lr=learning_rate)\n",
    "\n",
    "        print(full_model)\n",
    "        print(f\"Full model has {len(list(full_model.children()))} layers\")\n",
    "        \n",
    "        # Print trainable parameters\n",
    "        trainable_params = sum(p.numel() for p in full_model.parameters() if p.requires_grad)\n",
    "        total_params = sum(p.numel() for p in full_model.parameters())\n",
    "        print(f\"Trainable parameters: {trainable_params:,} / {total_params:,} ({100*trainable_params/total_params:.1f}%)\")\n",
    "\n",
    "        logger.info(f\"{model_name} model prepared with {classes} classes, freeze_all={freeze_all}, freeze_till={freeze_till}, learning_rate={learning_rate}\")\n",
    "\n",
    "        return full_model, optimizer, criterion\n",
    "\n",
    "    def update_base_model(self):\n",
    "        model, optimizer, criterion = self.prepare_full_model(\n",
    "            model = self.model,\n",
    "            classes = self.config.params_classes,\n",
    "            freeze_all = True,\n",
    "            freeze_till = None,\n",
    "            learning_rate = self.config.params_learning_rate,\n",
    "            model_name = self.config.model_name\n",
    "        )\n",
    "\n",
    "        self.save_model(path = self.config.updated_base_model_path, model = model)\n",
    "\n",
    "        logger.info(f'Updated {self.config.model_name} base model saved at {self.config.updated_base_model_path}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66656db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-19 18:18:38,388: INFO: common]: yaml file successfully loaded from config/config.yaml\n",
      "[2025-07-19 18:18:38,393: INFO: common]: yaml file successfully loaded from params.yaml\n",
      "[2025-07-19 18:18:38,393: INFO: common]: Directory created at: artifacts\n",
      "[2025-07-19 18:18:38,394: INFO: common]: Directory created at: artifacts/model_preparation\n",
      "[2025-07-19 18:18:38,929: INFO: 1616009934]: Created ResNet50 model with include_top=False\n",
      "[2025-07-19 18:18:38,929: INFO: 4035689665]: resnet50 model created successfully\n",
      "Frozen: 0.weight\n",
      "Frozen: 1.weight\n",
      "Frozen: 1.bias\n",
      "Frozen: 4.0.conv1.weight\n",
      "Frozen: 4.0.bn1.weight\n",
      "Frozen: 4.0.bn1.bias\n",
      "Frozen: 4.0.conv2.weight\n",
      "Frozen: 4.0.bn2.weight\n",
      "Frozen: 4.0.bn2.bias\n",
      "Frozen: 4.0.conv3.weight\n",
      "Frozen: 4.0.bn3.weight\n",
      "Frozen: 4.0.bn3.bias\n",
      "Frozen: 4.0.downsample.0.weight\n",
      "Frozen: 4.0.downsample.1.weight\n",
      "Frozen: 4.0.downsample.1.bias\n",
      "Frozen: 4.1.conv1.weight\n",
      "Frozen: 4.1.bn1.weight\n",
      "Frozen: 4.1.bn1.bias\n",
      "Frozen: 4.1.conv2.weight\n",
      "Frozen: 4.1.bn2.weight\n",
      "Frozen: 4.1.bn2.bias\n",
      "Frozen: 4.1.conv3.weight\n",
      "Frozen: 4.1.bn3.weight\n",
      "Frozen: 4.1.bn3.bias\n",
      "Frozen: 4.2.conv1.weight\n",
      "Frozen: 4.2.bn1.weight\n",
      "Frozen: 4.2.bn1.bias\n",
      "Frozen: 4.2.conv2.weight\n",
      "Frozen: 4.2.bn2.weight\n",
      "Frozen: 4.2.bn2.bias\n",
      "Frozen: 4.2.conv3.weight\n",
      "Frozen: 4.2.bn3.weight\n",
      "Frozen: 4.2.bn3.bias\n",
      "Frozen: 5.0.conv1.weight\n",
      "Frozen: 5.0.bn1.weight\n",
      "Frozen: 5.0.bn1.bias\n",
      "Frozen: 5.0.conv2.weight\n",
      "Frozen: 5.0.bn2.weight\n",
      "Frozen: 5.0.bn2.bias\n",
      "Frozen: 5.0.conv3.weight\n",
      "Frozen: 5.0.bn3.weight\n",
      "Frozen: 5.0.bn3.bias\n",
      "Frozen: 5.0.downsample.0.weight\n",
      "Frozen: 5.0.downsample.1.weight\n",
      "Frozen: 5.0.downsample.1.bias\n",
      "Frozen: 5.1.conv1.weight\n",
      "Frozen: 5.1.bn1.weight\n",
      "Frozen: 5.1.bn1.bias\n",
      "Frozen: 5.1.conv2.weight\n",
      "Frozen: 5.1.bn2.weight\n",
      "Frozen: 5.1.bn2.bias\n",
      "Frozen: 5.1.conv3.weight\n",
      "Frozen: 5.1.bn3.weight\n",
      "Frozen: 5.1.bn3.bias\n",
      "Frozen: 5.2.conv1.weight\n",
      "Frozen: 5.2.bn1.weight\n",
      "Frozen: 5.2.bn1.bias\n",
      "Frozen: 5.2.conv2.weight\n",
      "Frozen: 5.2.bn2.weight\n",
      "Frozen: 5.2.bn2.bias\n",
      "Frozen: 5.2.conv3.weight\n",
      "Frozen: 5.2.bn3.weight\n",
      "Frozen: 5.2.bn3.bias\n",
      "Frozen: 5.3.conv1.weight\n",
      "Frozen: 5.3.bn1.weight\n",
      "Frozen: 5.3.bn1.bias\n",
      "Frozen: 5.3.conv2.weight\n",
      "Frozen: 5.3.bn2.weight\n",
      "Frozen: 5.3.bn2.bias\n",
      "Frozen: 5.3.conv3.weight\n",
      "Frozen: 5.3.bn3.weight\n",
      "Frozen: 5.3.bn3.bias\n",
      "Frozen: 6.0.conv1.weight\n",
      "Frozen: 6.0.bn1.weight\n",
      "Frozen: 6.0.bn1.bias\n",
      "Frozen: 6.0.conv2.weight\n",
      "Frozen: 6.0.bn2.weight\n",
      "Frozen: 6.0.bn2.bias\n",
      "Frozen: 6.0.conv3.weight\n",
      "Frozen: 6.0.bn3.weight\n",
      "Frozen: 6.0.bn3.bias\n",
      "Frozen: 6.0.downsample.0.weight\n",
      "Frozen: 6.0.downsample.1.weight\n",
      "Frozen: 6.0.downsample.1.bias\n",
      "Frozen: 6.1.conv1.weight\n",
      "Frozen: 6.1.bn1.weight\n",
      "Frozen: 6.1.bn1.bias\n",
      "Frozen: 6.1.conv2.weight\n",
      "Frozen: 6.1.bn2.weight\n",
      "Frozen: 6.1.bn2.bias\n",
      "Frozen: 6.1.conv3.weight\n",
      "Frozen: 6.1.bn3.weight\n",
      "Frozen: 6.1.bn3.bias\n",
      "Frozen: 6.2.conv1.weight\n",
      "Frozen: 6.2.bn1.weight\n",
      "Frozen: 6.2.bn1.bias\n",
      "Frozen: 6.2.conv2.weight\n",
      "Frozen: 6.2.bn2.weight\n",
      "Frozen: 6.2.bn2.bias\n",
      "Frozen: 6.2.conv3.weight\n",
      "Frozen: 6.2.bn3.weight\n",
      "Frozen: 6.2.bn3.bias\n",
      "Frozen: 6.3.conv1.weight\n",
      "Frozen: 6.3.bn1.weight\n",
      "Frozen: 6.3.bn1.bias\n",
      "Frozen: 6.3.conv2.weight\n",
      "Frozen: 6.3.bn2.weight\n",
      "Frozen: 6.3.bn2.bias\n",
      "Frozen: 6.3.conv3.weight\n",
      "Frozen: 6.3.bn3.weight\n",
      "Frozen: 6.3.bn3.bias\n",
      "Frozen: 6.4.conv1.weight\n",
      "Frozen: 6.4.bn1.weight\n",
      "Frozen: 6.4.bn1.bias\n",
      "Frozen: 6.4.conv2.weight\n",
      "Frozen: 6.4.bn2.weight\n",
      "Frozen: 6.4.bn2.bias\n",
      "Frozen: 6.4.conv3.weight\n",
      "Frozen: 6.4.bn3.weight\n",
      "Frozen: 6.4.bn3.bias\n",
      "Frozen: 6.5.conv1.weight\n",
      "Frozen: 6.5.bn1.weight\n",
      "Frozen: 6.5.bn1.bias\n",
      "Frozen: 6.5.conv2.weight\n",
      "Frozen: 6.5.bn2.weight\n",
      "Frozen: 6.5.bn2.bias\n",
      "Frozen: 6.5.conv3.weight\n",
      "Frozen: 6.5.bn3.weight\n",
      "Frozen: 6.5.bn3.bias\n",
      "Frozen: 7.0.conv1.weight\n",
      "Frozen: 7.0.bn1.weight\n",
      "Frozen: 7.0.bn1.bias\n",
      "Frozen: 7.0.conv2.weight\n",
      "Frozen: 7.0.bn2.weight\n",
      "Frozen: 7.0.bn2.bias\n",
      "Frozen: 7.0.conv3.weight\n",
      "Frozen: 7.0.bn3.weight\n",
      "Frozen: 7.0.bn3.bias\n",
      "Frozen: 7.0.downsample.0.weight\n",
      "Frozen: 7.0.downsample.1.weight\n",
      "Frozen: 7.0.downsample.1.bias\n",
      "Frozen: 7.1.conv1.weight\n",
      "Frozen: 7.1.bn1.weight\n",
      "Frozen: 7.1.bn1.bias\n",
      "Frozen: 7.1.conv2.weight\n",
      "Frozen: 7.1.bn2.weight\n",
      "Frozen: 7.1.bn2.bias\n",
      "Frozen: 7.1.conv3.weight\n",
      "Frozen: 7.1.bn3.weight\n",
      "Frozen: 7.1.bn3.bias\n",
      "Frozen: 7.2.conv1.weight\n",
      "Frozen: 7.2.bn1.weight\n",
      "Frozen: 7.2.bn1.bias\n",
      "Frozen: 7.2.conv2.weight\n",
      "Frozen: 7.2.bn2.weight\n",
      "Frozen: 7.2.bn2.bias\n",
      "Frozen: 7.2.conv3.weight\n",
      "Frozen: 7.2.bn3.weight\n",
      "Frozen: 7.2.bn3.bias\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (5): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (6): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (7): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=4, bias=True)\n",
      ")\n",
      "Full model has 10 layers\n",
      "Trainable parameters: 8,196 / 23,516,228 (0.0%)\n",
      "[2025-07-19 18:18:38,932: INFO: 4035689665]: resnet50 model prepared with 4 classes, freeze_all=True, freeze_till=None, learning_rate=0.01\n",
      "[2025-07-19 18:18:39,053: INFO: 4035689665]: Updated resnet50 base model saved at artifacts/model_preparation/updated_base_model_resnet50.pth\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    base_model_config = config.get_model_preparation_config()\n",
    "    prepare_base_model = ModelPreparation(config=base_model_config)\n",
    "    prepare_base_model.get_base_model()\n",
    "    prepare_base_model.update_base_model()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-cancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
